\documentclass{article}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage{todonotes}
\renewcommand{\baselinestretch}{1.2} 

\newcommand{\comment}[1]{\todo[inline]{#1}}

\title{\textbf{A decomposition based on constrained clustering algorithms for job shop scheduling problems} \\}


\author{\\[1in] Student: \\ \textit{\textbf{Mohammed El-Kholany, MSc.}}\\Alpen-Adria-Universität Klagenfurt, Austria \\[3in] }
\date{April 2021}

\begin{document}

\clearpage\maketitle
\thispagestyle{empty}
\clearpage
\setcounter{page}{1}
\newpage
\section{Introduction}
Nowadays, the massive progress and development of the internet and online technologies, data generated by machines and devices, product development, quality and inventory management systems, or production planning systems has become huge and is expected to increase in the coming years. Hence, to capture long-term revenues and sustainable competitive advantages, companies must manage the knowledge and have the valuable information to make the right decision at the right time \cite{benabdellah2019survey}.

It can be assumed that knowledge management is a crucial issue in the industry. To extract implicit, unknown, and potentially useful information from data, we use data mining techniques that have been responsible for many of artificial intelligence’s recent successes. 
Clustering is one of these techniques, which is applied whenever the extracted data is not labeled, i.e., the semantics of this data is with respect to the application is unclear. Therefore, clustering has always been an exploratory but critical task in the knowledge discovery process, with applications ranging from image processing, production systems, and information retrieval \cite{benabdellah2019survey}. Clustering is a technique that aims to partition a dataset (objects) into subsets by identifying similar objects and aggregating them in the same cluster while the dissimilar objects should belong to different clusters.

\comment{The next paragraph jumps to a distance, which is one of the similarity measures in the Euclidean space. One should explain this transition.}

Furthermore, from an optimization perspective, the main objective is to minimize the distance between objects falling in the same cluster and maximize the distance between the others that belong to different clusters. Since clustering does not use a subset of the dataset as labels to learn a classification model, clustering differs from classification \cite{wagstaff2001constrained}. In other words, with the terminology of machine learning, clustering is a form of an unsupervised task, which calculates the similarity between data objects without knowing the proper attribution~\cite{li2018geometric}. Due to these unsupervised characteristics, clustering is known as one of the most challenging machine learning tasks \cite{benabdellah2019survey}.

Clustering has been widely applied in several disciplines; one is production-planning systems, more specifically scheduling. 
\comment{Are there any citations for the claim above?}
Scheduling is one of the most complex problems in the industry. Scheduling of operations involves resource allocation over a period of time to perform a series of tasks, where one of the most critical problems is the Job-shop Scheduling Problem (JSP). The JSP has been known as a complex and combinatorial optimization problem, and it has been proven to be NP-hard \cite{baker1974introduction,lenstra1979computational}. Therefore, it is very difficult to reach an optimal solution in a reasonable time, even for small instances. However, from a practical perspective, the JSP scale is large, where the number of operations can be up to 10,000s in some workshops \cite{zhang2010hybrid}.

\section{Project Objective}
The main objective is to find the most appropriate sequence of operations to optimize the typical performance indicator (makespan). Several approaches have been studied to solve JSP, and one of the most effective approaches used is decomposition \cite{zhang2010hybrid,zhai2014decomposition}. The main idea of the decomposition is to split the problem into a series of sub-problems (windows) and solve each of them separately in a sequence, and then obtain the solution of the original problem.

This project intends to apply the clustering technique to decompose the problem into sub-problems, where the number of clusters corresponds to the number of sub-problems (windows), and the operations correspond to data objects. For the JSP, an instance consists of a set of jobs to be processed on machines. The number of jobs is $n$, and the number of machines is $m$. Each job contains $m$ operations with the operation precedence constraints. Each operation should be executed on machine $m$ for a certain amount of time. Since the problem at hand has precedence constraints, it is required to apply a constrained clustering approach for the decomposition \cite{wagstaff2001constrained}.

In the context of partitioning algorithms, instance-level constraints are helpful to express a priori knowledge about which operations should or should not be grouped. Consequently, two types of pairwise constraints will be considered:

\begin{enumerate}
    \item Must link constraints specify that two operations should be in the same window.
    \item Cannot link constraints specify that two operations must not be in the same window.
\end{enumerate}

It can be said that the attributes of the classical JSP are quite a few and not sufficient to define the similarity and dissimilarity between the operations. The lack of these attributes guides me to extract more features that could specify which operations are similar and should be in the same window and which shall not be in the same window. The main contribution of this project is to extract some features that have a significant impact on the decomposition process and accordingly on the makespan. 
\comment{Both I and we are used in the proposal, please select only one.}
More specifically, I need to extract some features to define which operations are similar to be scheduled in the same window and get a near-optimal solution in a reasonable time. 

\subsection{Feature extraction}
Some features could be extracted:
\begin{enumerate}
    \item The earliest starting time (EST) of an operation, the smaller the EST difference between the two operations, the more similarity.
    \item Work Remaining (WR) of a job, an operation that belongs to a higher WR job, will have a higher probability of being in an earlier window.
    \item Rank of operations sharing the same machine; the smaller difference in the rank, the more similarity.
    \item Distance between operations sharing the same machine (using EST); the smaller distance, the more similarity.
\end{enumerate}

\section{Dataset Selection}
I will use the benchmark instances presented in \cite{taillard1993benchmarks} as a dataset to work on. Many researchers have studied these instances and presented different approaches to solving them. I also developed different decomposition strategies to solve those. Therefore, it will be possible to measure the success/failure of my proposed model by comparing the results of the strategies developed in the past with those obtained from the proposed project. 

\comment{Maybe a good idea would be to consider also some real-world instances just to test the selected similarity function and clustering algorithms.}

\newpage
\bibliographystyle{ieeetr.bst}
\bibliography{references.bib}
\end{document}

